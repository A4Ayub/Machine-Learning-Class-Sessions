{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rodhiambo2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\rodhiambo2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet') # Needed because we will require Lemmatizer\n",
    "nltk.download('reuters') # Needed because we will require reuters dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,reuters\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import ngrams\n",
    "\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'just', 'a', 'test']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to verify that the imports don't fail and that we have the correct files from nltk download\n",
    "reuters.fileids()\n",
    "stopwords.words('english')\n",
    "word_tokenize('This is just a test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Text Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will address the binary problem of detecting Sports related documents Vs any other type of documents. In order to do this we will create an artificial (and very small collection);\n",
    "\n",
    "1. Define a set of labelled documents that will be our training dataset. These are the documents the classifier will learn from in order to categorise future unseen documents\n",
    "2. Define a set of labelled documents that will be our testing dataset. These will be the \"unseen\" documents that the classifier will predic (without having being trained with them)\n",
    "3. Represent our training and testing documents\n",
    "4. Train the classifier based on the training data\n",
    "5. Predict the labels for the testing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ['Football: a great sport','The referee has been very bad this season',\n",
    "            'Our team scored 5 goals','I love tenis','Politics is in the increase in kenya',\n",
    "            'exit means exit','The parliament wants to create new legislation',\n",
    "             'I also want to travel the world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Football: a great sport',\n",
       " 'The referee has been very bad this season',\n",
       " 'Our team scored 5 goals',\n",
       " 'I love tenis',\n",
       " 'Politics is in the increase in kenya',\n",
       " 'exit means exit',\n",
       " 'The parliament wants to create new legislation',\n",
       " 'I also want to travel the world']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [\"Sports\",\"Sports\",\"Sports\",\"Sports\",\"Non Sports\",\"Non Sports\",\"Non Sports\",\n",
    "                \"Non Sports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports',\n",
       " 'Sports',\n",
       " 'Sports',\n",
       " 'Sports',\n",
       " 'Non Sports',\n",
       " 'Non Sports',\n",
       " 'Non Sports',\n",
       " 'Non Sports']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['Swimming is a great sport',\n",
    "            'alot of policy changes wll happen after Exit',\n",
    "            'The table tenis team will travel to the UK soon for the European Championship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Swimming is a great sport',\n",
       " 'alot of policy changes wll happen after Exit',\n",
       " 'The table tenis team will travel to the UK soon for the European Championship']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [\"Sports\",\"Non Sports\",\"Sports\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports', 'Non Sports', 'Sports']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation of the data using the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorised_train_data = vectorizer.fit_transform(train_data)\n",
    "vectorised_test_data = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x34 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.5773502691896258\n",
      "  (0, 7)\t0.5773502691896258\n",
      "  (0, 23)\t0.5773502691896258\n",
      "  (1, 26)\t0.23306022298531667\n",
      "  (1, 20)\t0.36755620220626206\n",
      "  (1, 8)\t0.36755620220626206\n",
      "  (1, 2)\t0.36755620220626206\n",
      "  (1, 30)\t0.36755620220626206\n",
      "  (1, 1)\t0.36755620220626206\n",
      "  (1, 27)\t0.36755620220626206\n",
      "  (1, 22)\t0.36755620220626206\n",
      "  (2, 17)\t0.5\n",
      "  (2, 24)\t0.5\n",
      "  (2, 21)\t0.5\n",
      "  (2, 6)\t0.5\n",
      "  (3, 14)\t0.7071067811865475\n",
      "  (3, 25)\t0.7071067811865475\n",
      "  (4, 26)\t0.21875176319808765\n",
      "  (4, 19)\t0.3449905190903309\n",
      "  (4, 11)\t0.3449905190903309\n",
      "  (4, 9)\t0.6899810381806618\n",
      "  (4, 10)\t0.3449905190903309\n",
      "  (4, 12)\t0.3449905190903309\n",
      "  (5, 4)\t0.894427190999916\n",
      "  (5, 15)\t0.447213595499958\n",
      "  (6, 26)\t0.2566384596871779\n",
      "  (6, 18)\t0.40474112817023666\n",
      "  (6, 32)\t0.40474112817023666\n",
      "  (6, 28)\t0.3392046533389727\n",
      "  (6, 3)\t0.40474112817023666\n",
      "  (6, 16)\t0.40474112817023666\n",
      "  (6, 13)\t0.40474112817023666\n",
      "  (7, 26)\t0.28065362276760947\n",
      "  (7, 28)\t0.37094601851668646\n",
      "  (7, 0)\t0.4426151249601719\n",
      "  (7, 31)\t0.4426151249601719\n",
      "  (7, 29)\t0.4426151249601719\n",
      "  (7, 33)\t0.4426151249601719\n"
     ]
    }
   ],
   "source": [
    "print(vectorised_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(vectorised_train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports' 'Non Sports' 'Non Sports']\n"
     ]
    }
   ],
   "source": [
    "# print the predictions based on the test data\n",
    "print(classifier.predict(vectorised_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Matching problems (e.g. car is differnet from \"Cars\")\n",
    "2. Cases the model has never seen before\n",
    "3. \"Spurious\" correlations and bias (\"car\" appears only in the positive category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing the Common Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('sport', 0.5773502691896258),\n",
      "  ('is', 0.5773502691896258),\n",
      "  ('great', 0.5773502691896258)],\n",
      " [('exit', 1.0)],\n",
      " [('travel', 0.36958797589810716),\n",
      "  ('to', 0.30974356821489196),\n",
      "  ('the', 0.7030455932328479),\n",
      "  ('tenis', 0.36958797589810716),\n",
      "  ('team', 0.36958797589810716)]]\n"
     ]
    }
   ],
   "source": [
    "## Function to show the feature weights of a document\n",
    "from pprint import pprint\n",
    "\n",
    "def feature_values(doc, representer):\n",
    "    doc_representation = representer.transform([doc])\n",
    "    features = representer.get_feature_names()\n",
    "    return [(features[index],doc_representation[0, index]) for index in doc_representation.nonzero()[1]]\n",
    "\n",
    "pprint([feature_values(doc, vectorizer) for doc in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "s_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "s_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x25 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vectorised_train_data = s_vectorizer.fit_transform(train_data)\n",
    "s_vectorised_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x17 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_vectorised_test_data = s_vectorizer.fit_transform(test_data)\n",
    "s_vectorised_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports' 'Non Sports' 'Non Sports']\n"
     ]
    }
   ],
   "source": [
    "classifier = LinearSVC()\n",
    "classifier.fit(vectorised_train_data,train_labels)\n",
    "\n",
    "print(classifier.predict(vectorised_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
